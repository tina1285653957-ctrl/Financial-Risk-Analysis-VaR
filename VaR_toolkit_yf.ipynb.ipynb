{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6c9065",
   "metadata": {},
   "source": [
    "# VaR Toolkit — Reusable Risk Analysis (Parametric / Historical / Monte Carlo)\n",
    "\n",
    "This notebook computes Value-at-Risk (VaR), Expected Shortfall (ES), and basic backtesting.  \n",
    "It is **reusable**: change a few parameters and rerun.\n",
    "\n",
    "**Data sources (choose one):**\n",
    "- **yfinance** (default, no token)\n",
    "- **TuShare** (optional, requires a token; set via `.env` or code cell)\n",
    "- CSV (optional fallback)\n",
    "\n",
    "Outputs: figures in `./figures/` and a summary CSV in `./outputs/summary.csv`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9688b136",
   "metadata": {},
   "source": [
    "## 0. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Edit these ----\n",
    "SYMBOL = \"600036.SS\"   # e.g., '600036.SS' (CMB); US tickers like 'AAPL'; HK '0700.HK'\n",
    "START  = \"2018-01-01\"\n",
    "END    = \"2025-01-01\"\n",
    "\n",
    "DATA_SOURCE = \"yfinance\"   # \"yfinance\" (default) | \"tushare\" | \"csv\"\n",
    "CSV_PATH    = \"zhaoshang.csv\"  # only used if DATA_SOURCE='csv'\n",
    "\n",
    "CONF_LEVELS = [0.95, 0.99]\n",
    "HORIZONS    = [1, 10]\n",
    "\n",
    "MC_SEED = 42\n",
    "MC_N    = 100000\n",
    "\n",
    "FIG_DIR = \"figures\"\n",
    "OUT_DIR = \"outputs\"\n",
    "# --------------------\n",
    "\n",
    "import os, math, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.stats import norm\n",
    "\n",
    "pd.options.display_float_format = \"{:.6f}\".format\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "Path(FIG_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"SYMBOL:\", SYMBOL, \"|\", START, \"→\", END, \"| Source:\", DATA_SOURCE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc535e30",
   "metadata": {},
   "source": [
    "## 1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_yfinance(symbol, start, end):\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "    except Exception as e:\n",
    "        raise ImportError(\"yfinance not installed. `pip install yfinance`.\")\n",
    "    data = yf.download(symbol, start=start, end=end, progress=False)\n",
    "    if data is None or len(data)==0:\n",
    "        raise ValueError(\"No data from yfinance. Check symbol or dates.\")\n",
    "    df = data.reset_index()[[\"Date\",\"Adj Close\"]].rename(columns={\"Date\":\"datetime\",\"Adj Close\":\"close\"})\n",
    "    return df\n",
    "\n",
    "def load_tushare(symbol, start, end):\n",
    "    # TuShare requires a token. Put it in .env as TUSHARE_TOKEN or set TS_TOKEN in code.\n",
    "    token = os.getenv(\"TUSHARE_TOKEN\", os.getenv(\"TS_TOKEN\", \"\")).strip()\n",
    "    if not token:\n",
    "        raise ValueError(\"Missing TuShare token. Set TUSHARE_TOKEN in environment/.env.\")\n",
    "    try:\n",
    "        import tushare as ts\n",
    "    except Exception:\n",
    "        raise ImportError(\"tushare not installed. `pip install tushare`.\")\n",
    "    ts.set_token(token)\n",
    "    pro = ts.pro_api(token)\n",
    "    # Convert dates to YYYYMMDD\n",
    "    s = pd.Timestamp(start).strftime(\"%Y%m%d\")\n",
    "    e = pd.Timestamp(end).strftime(\"%Y%m%d\")\n",
    "    # For A-share, TuShare uses ts_code like '600036.SH'\n",
    "    ts_code = symbol if symbol.endswith((\".SH\", \".SZ\")) else symbol\n",
    "    df = pro.daily(ts_code=ts_code, start_date=s, end_date=e)\n",
    "    if df is None or len(df)==0:\n",
    "        raise ValueError(\"No data from TuShare. Check ts_code and date window.\")\n",
    "    df[\"trade_date\"] = pd.to_datetime(df[\"trade_date\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "    df = df.rename(columns={\"trade_date\":\"datetime\", \"close\":\"close\"})[[\"datetime\",\"close\"]]\n",
    "    df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # date column detection\n",
    "    for c in [\"datetime\",\"trade_date\",\"date\",\"Date\"]:\n",
    "        if c in df.columns:\n",
    "            date_col = c\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"CSV must include one date column: datetime/trade_date/date/Date\")\n",
    "    if date_col == \"trade_date\":\n",
    "        df[date_col] = pd.to_datetime(df[date_col].astype(str), format=\"%Y%m%d\", errors=\"coerce\")\n",
    "    else:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    # price column detection\n",
    "    for c in [\"close\",\"Close\",\"Adj Close\",\"adj_close\",\"AdjClose\"]:\n",
    "        if c in df.columns:\n",
    "            price_col = c\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"CSV must include a price column like close/Adj Close\")\n",
    "    df = df[[date_col, price_col]].rename(columns={date_col:\"datetime\", price_col:\"close\"})\n",
    "    df = df.sort_values(\"datetime\").dropna().reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "if DATA_SOURCE == \"yfinance\":\n",
    "    raw = load_yfinance(SYMBOL, START, END)\n",
    "elif DATA_SOURCE == \"tushare\":\n",
    "    raw = load_tushare(SYMBOL, START, END)\n",
    "elif DATA_SOURCE == \"csv\":\n",
    "    if not os.path.exists(CSV_PATH):\n",
    "        raise FileNotFoundError(f\"CSV not found: {CSV_PATH}\")\n",
    "    raw = load_csv(CSV_PATH)\n",
    "else:\n",
    "    raise ValueError(\"Unknown DATA_SOURCE. Use 'yfinance' | 'tushare' | 'csv'.\")\n",
    "\n",
    "# window filter (also keeps consistency between loaders)\n",
    "raw = raw[(raw[\"datetime\"]>=START) & (raw[\"datetime\"]<=END)].copy().sort_values(\"datetime\")\n",
    "print(\"Data window:\", raw[\"datetime\"].min().date(), \"→\", raw[\"datetime\"].max().date(), \"| points:\", len(raw))\n",
    "raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13e2ee7",
   "metadata": {},
   "source": [
    "## 2. Returns and basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = raw.copy()\n",
    "df[\"ret\"] = np.log(df[\"close\"] / df[\"close\"].shift(1))\n",
    "ret = df[\"ret\"].dropna()\n",
    "\n",
    "mu, sig = ret.mean(), ret.std(ddof=1)\n",
    "ann_mu, ann_vol = mu*252, sig*np.sqrt(252)\n",
    "\n",
    "print(f\"Daily mean: {mu:.6f}, Daily vol: {sig:.6f}\")\n",
    "print(f\"Annualized return: {ann_mu:.4%}, Annualized volatility: {ann_vol:.4%}\")\n",
    "ret.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05014b",
   "metadata": {},
   "source": [
    "## 3. VaR methods and ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def var_parametric(mu, sigma, alpha=0.95, horizon_days=1, value=1.0):\n",
    "    z = norm.ppf(1 - alpha)\n",
    "    mu_h = mu * horizon_days\n",
    "    sig_h = sigma * math.sqrt(horizon_days)\n",
    "    return float(max(0.0, -(mu_h + z*sig_h) * value))\n",
    "\n",
    "def var_historical(returns, alpha=0.95, horizon_days=1, value=1.0):\n",
    "    losses = -returns\n",
    "    if horizon_days == 1:\n",
    "        q = losses.quantile(alpha)\n",
    "    else:\n",
    "        q = losses.quantile(alpha) * math.sqrt(horizon_days)\n",
    "    return float(q * value)\n",
    "\n",
    "def var_monte_carlo(mu, sigma, alpha=0.95, horizon_days=1, value=1.0, n=100000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    sim = rng.normal(loc=mu*horizon_days, scale=sigma*math.sqrt(horizon_days), size=n)\n",
    "    losses = -sim * value\n",
    "    return float(np.quantile(losses, alpha))\n",
    "\n",
    "def es_parametric(mu, sigma, alpha=0.95, horizon_days=1, value=1.0):\n",
    "    z = norm.ppf(1 - alpha)\n",
    "    mu_h = mu * horizon_days\n",
    "    sig_h = sigma * math.sqrt(horizon_days)\n",
    "    es = value * (-(mu_h) + (norm.pdf(z) / (1 - alpha)) * sig_h)\n",
    "    return float(max(0.0, es))\n",
    "\n",
    "rows = []\n",
    "for a in CONF_LEVELS:\n",
    "    for h in HORIZONS:\n",
    "        rows.append({\n",
    "            \"alpha\": a, \"horizon_d\": h,\n",
    "            \"VaR_param\": var_parametric(mu, sig, a, h),\n",
    "            \"VaR_hist\":  var_historical(ret, a, h),\n",
    "            \"VaR_mc\":    var_monte_carlo(mu, sig, a, h, n=MC_N, seed=MC_SEED),\n",
    "            \"ES_param\":  es_parametric(mu, sig, a, h)\n",
    "        })\n",
    "res = pd.DataFrame(rows)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a03b6",
   "metadata": {},
   "source": [
    "## 4. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.1 Distribution with normal overlay\n",
    "fig = plt.figure()\n",
    "plt.hist(ret, bins=60, density=True, alpha=0.6, label=\"Empirical\")\n",
    "x = np.linspace(ret.min(), ret.max(), 400)\n",
    "pdf = (1/(sig*np.sqrt(2*np.pi))) * np.exp(-0.5*((x - mu)/sig)**2)\n",
    "plt.plot(x, pdf, label=\"Normal fit\")\n",
    "plt.title(\"Daily Log-Returns — Empirical vs Normal\")\n",
    "plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "plt.savefig(f\"{FIG_DIR}/return_distribution.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# 4.2 Rolling volatility\n",
    "roll_win = 60\n",
    "rolling_vol = ret.rolling(roll_win).std() * np.sqrt(252)\n",
    "fig = plt.figure()\n",
    "plt.plot(rolling_vol.index, rolling_vol.values, label=f\"Rolling Vol ({roll_win}d, annualized)\")\n",
    "plt.title(\"Rolling Volatility\")\n",
    "plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "plt.savefig(f\"{FIG_DIR}/rolling_vol.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# 4.3 VaR comparison (1d, first alpha)\n",
    "alpha = CONF_LEVELS[0] if len(CONF_LEVELS)>0 else 0.95\n",
    "V_p = var_parametric(mu, sig, alpha, 1)\n",
    "V_h = var_historical(ret, alpha, 1)\n",
    "V_m = var_monte_carlo(mu, sig, alpha, 1, n=MC_N, seed=MC_SEED)\n",
    "\n",
    "ret_ts = pd.Series(ret.values, index=df.loc[ret.index, \"datetime\"])\n",
    "fig = plt.figure()\n",
    "plt.plot(ret_ts, label=\"Daily Return\")\n",
    "plt.axhline(-V_p, linestyle=\"--\", label=f\"Parametric VaR {int(alpha*100)}%\")\n",
    "plt.axhline(-V_h, linestyle=\"--\", label=f\"Hist VaR {int(alpha*100)}%\")\n",
    "plt.axhline(-V_m, linestyle=\"--\", label=f\"MC VaR {int(alpha*100)}%\")\n",
    "plt.title(\"Returns with VaR Thresholds (1d)\")\n",
    "plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "plt.savefig(f\"{FIG_DIR}/var_comparison_1d_{int(alpha*100)}.png\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb468187",
   "metadata": {},
   "source": [
    "## 5. Backtesting (Parametric 1d, 95%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bbf85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha_bt = 0.95\n",
    "V_bt = var_parametric(mu, sig, alpha_bt, 1)\n",
    "ret_ts = pd.Series(ret.values, index=df.loc[ret.index, \"datetime\"])\n",
    "\n",
    "years = sorted(set(ret_ts.index.year))\n",
    "rows_bt = []\n",
    "for yr in years:\n",
    "    sel = ret_ts[ret_ts.index.year == yr]\n",
    "    if len(sel)==0: \n",
    "        continue\n",
    "    exceed = (sel < -V_bt).sum()\n",
    "    rows_bt.append({\"year\": int(yr), \"n_days\": int(len(sel)), \"exceed\": int(exceed), \"ratio\": exceed/len(sel)})\n",
    "bt = pd.DataFrame(rows_bt).sort_values(\"year\")\n",
    "bt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353b5f05",
   "metadata": {},
   "source": [
    "## 6. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "today = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "sumrow = {\n",
    "    \"symbol\": SYMBOL, \"start\": START, \"end\": END,\n",
    "    \"daily_mean\": mu, \"daily_vol\": sig,\n",
    "    \"ann_return\": ann_mu, \"ann_vol\": ann_vol,\n",
    "    \"generated_on\": today, \"source\": DATA_SOURCE\n",
    "}\n",
    "for a in CONF_LEVELS:\n",
    "    for h in HORIZONS:\n",
    "        sumrow[f\"VaR_param_{int(a*100)}_{h}d\"] = var_parametric(mu, sig, a, h)\n",
    "        sumrow[f\"VaR_hist_{int(a*100)}_{h}d\"]  = var_historical(ret, a, h)\n",
    "        sumrow[f\"VaR_mc_{int(a*100)}_{h}d\"]    = var_monte_carlo(mu, sig, a, h, n=MC_N, seed=MC_SEED)\n",
    "        sumrow[f\"ES_param_{int(a*100)}_{h}d\"]  = es_parametric(mu, sig, a, h)\n",
    "\n",
    "out_path = f\"{OUT_DIR}/summary.csv\"\n",
    "pd.DataFrame([sumrow]).to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "print(\"Summary saved to:\", out_path)\n",
    "print(\"Figures saved to:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0c13c",
   "metadata": {},
   "source": [
    "\n",
    "## Notes\n",
    "- Parametric VaR assumes normality; if tails are heavy, risk can be underestimated.\n",
    "- Historical VaR is non-parametric; depends on sample window.\n",
    "- Monte Carlo VaR follows the assumed distribution of returns; parameter choice matters.\n",
    "- Backtesting: for 95% VaR, theoretical exceedance ≈ 5% of trading days.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
